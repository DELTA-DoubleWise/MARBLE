command:
  - python
  - __main__.py
  - finetune
  # NOTE: must specify this parameter to update the argparser
  - --wandb_sweep

# program: __main__.py
method: bayes
metric:
  name: valid_aucroc
  goal: maximize
parameters:
  # ---- set sinlge value ----
  dataset:
    value: MTT
  feature_dir:
    value: data/MTT/hubert_features/HF_HuBERT_base_MPD_1Kh_HPO-baseline-v2_ckpt_134_250k_feature_layer_all_reduce_mean
  audio_dir:
    value: data/MTT/mp3
  metadata_dir:
    value: data/MTT
  num_outputs:
    value: 50
  monitor:
    value: valid_aucroc
  progress_bar_refresh_rate:
    value: 0
  max_epochs:
    value: 400
  lr_scheduler_patience: 
    distribution: categorical
    values: 
      - 1
      - 2
  earlystop_patience:
    value: 3
  # train in fine-tune mode

  pre_trained_folder:
    value: /share/project/music/music/hf_ckpt_short/HF_HuBERT_base_MPD_1Kh_HPO-baseline-v2_ckpt_134_250k
  reduction:
    value: mean
  # ---- end sinlge value ----
  hidden_layer_sizes:
  # value: "[]"
    distribution: categorical
    values:
    - "[]"
    - "[512,]"
    - "[512,256]"
    - "[512,256,128]"
  layer:
    value: "all"
    # distribution: categorical
    # values:
    # - "all"
    # - "0"
    # - "1"
    # - "2"
    # - "3"
    # - "4"
    # - "5"
    # - "6"
    # - "7"
    # - "8"
    # - "9"
    # - "10"
    # - "11"
    # - "12"
  train_sample_duration:
    # value: 15
    distribution: categorical
    values:
    - 15
    - 30
  test_sample_duration:
    value: 30
  # for v100 16G, maximum batch_size is 2, hence we use grad accumulation
  batch_size:
    # distribution: int_uniform
    # min: 16
    # max: 24
    values:
    - 16
    - 20
    - 24
    # distribution: int_uniform
    # min: 64
    # max: 512
    # value: 8

  accumulate_grad_batches:
    distribution: categorical
    values:
    - 1
    - 2
    # - 8
  l2_weight_decay:
    distribution: categorical
    values:
    - 0.0
    - 0.00001
    - 0.0001
  lr:
    # distribution: log_uniform
    # min: -6
    # max: -4
    min: 0.000001
    max: 0.001
  dropout_p:
    distribution: uniform
    min: 0.2
    max: 0.8
  # num_layers:
  #   distribution: int_uniform
  #   min: 2
  #   max: 6
  # features_start:
  #   distribution: categorical
  #   values:
  #     - 8
  #     - 16
  #     - 32
  #     - 64
  #     - 128
  # bilinear:
  #   distribution: categorical
  #   values:
  #     - True
  #     - False